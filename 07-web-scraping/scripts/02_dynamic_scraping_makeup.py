"""
Dynamic Web Scraping with Playwright
====================================
This script demonstrates how to scrape makeup products from a brand website
using Playwright to handle JavaScript-rendered content.
"""

from playwright.sync_api import sync_playwright
import time
import json

def scrape_makeup_products(brand_url, max_products=5):
    """
    Scrape makeup products from a brand's website using Playwright.
    
    Args:
        brand_url: The URL of the makeup brand's website
        max_products: Maximum number of products to scrape
    """
    print(f"[v0] Launching browser to scrape: {brand_url}")
    
    with sync_playwright() as p:
        # Launch browser (headless=False to see what's happening)
        browser = p.chromium.launch(headless=False)
        
        # Create a new page
        page = browser.new_page()
        
        # Set viewport size
        page.set_viewport_size({"width": 1920, "height": 1080})
        
        try:
            print("[v0] Navigating to website...")
            page.goto(brand_url, wait_until="networkidle", timeout=30000)
            
            # Wait a bit for dynamic content to load
            time.sleep(2)
            
            print("[v0] Page loaded successfully!")
            print(f"[v0] Page title: {page.title()}")
            
            # Example 1: Scraping Sephora New Arrivals
            print("\n" + "=" * 60)
            print("SCRAPING MAKEUP PRODUCTS")
            print("=" * 60)
            
            products = []
            
            # Common selectors for product listings (adjust based on actual site)
            product_selectors = [
                'div[data-comp="ProductGrid"] div[data-comp="ProductTile"]',
                'div.product-grid div.product-tile',
                'div.product-list article',
                'div[class*="product"]',
            ]
            
            # Try to find products with different selectors
            for selector in product_selectors:
                try:
                    print(f"[v0] Trying selector: {selector}")
                    page.wait_for_selector(selector, timeout=5000)
                    product_elements = page.query_selector_all(selector)
                    
                    if product_elements:
                        print(f"[v0] Found {len(product_elements)} products!")
                        
                        for i, element in enumerate(product_elements[:max_products]):
                            try:
                                # Extract product information
                                # These selectors are examples - adjust for actual website
                                
                                # Try to find product name
                                name_element = element.query_selector('h3, h2, [class*="name"], [class*="title"]')
                                name = name_element.inner_text() if name_element else "Name not found"
                                
                                # Try to find price
                                price_element = element.query_selector('[class*="price"], [data-comp="Price"]')
                                price = price_element.inner_text() if price_element else "Price not found"
                                
                                # Try to find brand
                                brand_element = element.query_selector('[class*="brand"]')
                                brand = brand_element.inner_text() if brand_element else "Brand not found"
                                
                                # Try to find image
                                img_element = element.query_selector('img')
                                image_url = img_element.get_attribute('src') if img_element else None
                                
                                product = {
                                    'name': name.strip(),
                                    'price': price.strip(),
                                    'brand': brand.strip(),
                                    'image_url': image_url
                                }
                                
                                products.append(product)
                                
                                print(f"\n{i + 1}. {product['name']}")
                                print(f"   Brand: {product['brand']}")
                                print(f"   Price: {product['price']}")
                                
                            except Exception as e:
                                print(f"[v0] Error extracting product {i + 1}: {e}")
                                continue
                        
                        break  # Found products, exit loop
                        
                except Exception as e:
                    print(f"[v0] Selector failed: {e}")
                    continue
            
            if not products:
                print("\n[v0] No products found with standard selectors.")
                print("[v0] Let me show you the page structure...")
                
                # Get page content for inspection
                content = page.content()
                print(f"[v0] Page has {len(content)} characters of HTML")
                
                # Take a screenshot for debugging
                page.screenshot(path="scripts/makeup_page_screenshot.png")
                print("[v0] Screenshot saved to: scripts/makeup_page_screenshot.png")
            
            # Save results to JSON
            if products:
                with open('scripts/makeup_products.json', 'w', encoding='utf-8') as f:
                    json.dump(products, f, indent=2, ensure_ascii=False)
                print(f"\n[v0] Saved {len(products)} products to makeup_products.json")
            
            return products
            
        except Exception as e:
            print(f"[v0] Error during scraping: {e}")
            page.screenshot(path="scripts/error_screenshot.png")
            print("[v0] Error screenshot saved to: scripts/error_screenshot.png")
            return []
            
        finally:
            # Keep browser open for a moment to see results
            time.sleep(3)
            browser.close()
            print("\n[v0] Browser closed.")

def scrape_with_navigation():
    """
    Example of navigating to a specific section before scraping.
    """
    print("\n" + "=" * 60)
    print("ADVANCED: Navigation + Scraping")
    print("=" * 60)
    
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=False)
        page = browser.new_page()
        
        try:
            # Example: Navigate to Sephora and find New Arrivals
            print("[v0] Navigating to Sephora...")
            page.goto("https://www.sephora.com", wait_until="networkidle")
            
            # Wait for page to load
            time.sleep(2)
            
            # Try to find and click "New" or "New Arrivals" link
            print("[v0] Looking for 'New Arrivals' section...")
            
            # Multiple strategies to find the link
            new_arrivals_selectors = [
                'a:has-text("New")',
                'a:has-text("New Arrivals")',
                'a[href*="new"]',
                'nav a:has-text("What\'s New")'
            ]
            
            for selector in new_arrivals_selectors:
                try:
                    element = page.query_selector(selector)
                    if element:
                        print(f"[v0] Found link with selector: {selector}")
                        element.click()
                        page.wait_for_load_state("networkidle")
                        print(f"[v0] Navigated to: {page.url}")
                        break
                except:
                    continue
            
            # Now scrape products from this page
            time.sleep(2)
            
            # Take screenshot of the new page
            page.screenshot(path="scripts/new_arrivals_page.png")
            print("[v0] Screenshot saved: scripts/new_arrivals_page.png")
            
            # Extract products (using similar logic as before)
            print("\n[v0] Scraping products from New Arrivals...")
            
            time.sleep(3)
            
        except Exception as e:
            print(f"[v0] Error: {e}")
        finally:
            browser.close()

def print_scraping_guide():
    """
    Print a comprehensive guide for web scraping.
    """
    guide = """
    
    ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
    ‚ïë           WEB SCRAPING GUIDE FOR MAKEUP/FASHION              ‚ïë
    ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
    
    üìã STEP-BY-STEP PROCESS:
    
    1. INSPECT THE WEBSITE
       ‚Ä¢ Open browser DevTools (F12)
       ‚Ä¢ Find the HTML structure of products
       ‚Ä¢ Note class names, IDs, and data attributes
    
    2. CHOOSE YOUR TOOL
       ‚Ä¢ Static sites (HTML only) ‚Üí BeautifulSoup + Requests
       ‚Ä¢ Dynamic sites (JavaScript) ‚Üí Playwright or Selenium
    
    3. WRITE THE SCRAPER
       ‚Ä¢ Navigate to the page
       ‚Ä¢ Wait for content to load
       ‚Ä¢ Select elements using CSS selectors
       ‚Ä¢ Extract text, attributes, and data
    
    4. HANDLE EDGE CASES
       ‚Ä¢ Add error handling (try/except)
       ‚Ä¢ Handle missing elements gracefully
       ‚Ä¢ Add delays to avoid rate limiting
    
    5. STORE THE DATA
       ‚Ä¢ Save to JSON, CSV, or database
       ‚Ä¢ Clean and validate data
    
    ‚öñÔ∏è  LEGAL & ETHICAL CONSIDERATIONS:
    
    ‚úì Check robots.txt file (website.com/robots.txt)
    ‚úì Read Terms of Service
    ‚úì Add delays between requests (be respectful)
    ‚úì Use data responsibly
    ‚úì Don't overload servers
    
    üéØ COMMON SELECTORS FOR MAKEUP SITES:
    
    ‚Ä¢ Product containers: div.product, article.product-tile
    ‚Ä¢ Product names: h3.product-name, [data-comp="ProductName"]
    ‚Ä¢ Prices: span.price, [data-comp="Price"]
    ‚Ä¢ Images: img.product-image
    ‚Ä¢ Brands: span.brand-name
    
    üîß PLAYWRIGHT TIPS:
    
    ‚Ä¢ page.wait_for_selector() - Wait for element to appear
    ‚Ä¢ page.click() - Click buttons/links
    ‚Ä¢ page.fill() - Fill form inputs
    ‚Ä¢ page.screenshot() - Debug visually
    ‚Ä¢ page.evaluate() - Run JavaScript on page
    
    üì¶ POPULAR SITES TO PRACTICE:
    
    ‚Ä¢ Sephora - https://www.sephora.com
    ‚Ä¢ Ulta - https://www.ulta.com
    ‚Ä¢ Vogue - https://www.vogue.com
    ‚Ä¢ WWD - https://wwd.com
    
    """
    print(guide)

# Main execution
if __name__ == "__main__":
    print_scraping_guide()
    
    print("\n" + "=" * 60)
    print("STARTING MAKEUP SCRAPER")
    print("=" * 60)
    
    # Example: Scrape from Sephora's new arrivals
    # Note: URL might need adjustment based on current site structure
    sephora_url = "https://www.sephora.com/shop/makeup-new-arrivals"
    
    products = scrape_makeup_products(sephora_url, max_products=5)
    
    if products:
        print("\n‚úÖ Successfully scraped products!")
    else:
        print("\n‚ö†Ô∏è  No products found. Try adjusting selectors for the specific site.")
        print("üí° Use the navigation example to find the right page first.")
    
    # Uncomment to try the navigation example
    # scrape_with_navigation()
